{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b979c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1161e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"anger\", \"contempt\",\"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "model = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa6f5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the classifier as a support vector machines with linear kernel\n",
    "# clf = SVC(C=0.01, kernel='linear', decision_function_shape='ovo', probability=True)\n",
    "clf = SVC(kernel='linear', probability=True, tol=1e-5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6fda3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image):\n",
    "    detections = detector(image, 1)\n",
    "    # For all detected face instances individually\n",
    "    for k, d in enumerate(detections):\n",
    "        shape = model(image, d)# Get facial landmarks with prediction model\n",
    "        xpoint = []\n",
    "        ypoint = []\n",
    "        for i in range(0, 68):\n",
    "            xpoint.append(float(shape.part(i).x))\n",
    "            ypoint.append(float(shape.part(i).y))\n",
    "\n",
    "        # Center points of both axis\n",
    "        xcenter = np.mean(xpoint)\n",
    "        ycenter = np.mean(ypoint)\n",
    "        # Calculate distance between particular points and center point\n",
    "        xdistcent = [(x-xcenter) for x in xpoint]\n",
    "        ydistcent = [(y-ycenter) for y in ypoint]\n",
    "\n",
    "        # Prevent divided by 0 value\n",
    "        if xpoint[11] == xpoint[14]:\n",
    "            angle_nose = 0\n",
    "        else:\n",
    "            # Point 14 is the tip of the nose, point 11 is the top of the nose brigde\n",
    "            angle_nose = int(math.atan((ypoint[11]-ypoint[14])/(xpoint[11]-xpoint[14]))*180/math.pi)\n",
    "\n",
    "        # Get offset by finding how the nose brigde should be rotated to become perpendicular to the horizontal plane\n",
    "        if angle_nose < 0:\n",
    "            angle_nose += 90\n",
    "        else:\n",
    "            angle_nose -= 90\n",
    "\n",
    "        landmarks = []\n",
    "        for cx, cy, x, y in zip(xdistcent, ydistcent, xpoint, ypoint):\n",
    "            # Add the coordinates relative to the centre of gravity\n",
    "            landmarks.append(cx)\n",
    "            landmarks.append(cy)\n",
    "\n",
    "            # Get the euclidean distance between each point and the centre point (the vector length)\n",
    "            meanar = np.asarray((ycenter,xcenter))\n",
    "            centpar = np.asarray((y,x))\n",
    "            dist = np.linalg.norm(centpar-meanar)\n",
    "\n",
    "            # Get the angle the vector describes relative to the image, corrected for the offset that the nosebrigde\n",
    "            # has when the face is not perfectly horizontal\n",
    "            if x == xcenter:\n",
    "                angle_relative = 0\n",
    "            else:\n",
    "                angle_relative = (math.atan(float(y-ycenter)/(x-xcenter))*180/math.pi) - angle_nose\n",
    "            landmarks.append(dist)\n",
    "            landmarks.append(angle_relative)\n",
    "\n",
    "    if len(detections) < 1:\n",
    "        # In case no case selected, print \"error\" values\n",
    "        landmarks = \"error\"\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc820074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(emotion): #Define function to get file list, randomly shuffle it and split 80/20\n",
    "    path = os.path.join('CK+_Complete/', emotion)\n",
    "    path2 = os.path.join(path,'*')\n",
    "    files = glob.glob(path2)\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.8)] #get first 80% of file list\n",
    "    prediction = files[-int(len(files)*0.2):] #get last 20% of file list\n",
    "    return training, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7e4b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sets():\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    prediction_data = []\n",
    "    prediction_labels = []\n",
    "    for emotion in emotions:\n",
    "        \n",
    "        training, prediction = get_files(emotion)\n",
    "        #Append data to training and prediction list, and generate labels 0-7\n",
    "        for item in training:\n",
    "            #image_preprocessing(no need to crop the images of the dataset, already cropped !)\n",
    "            image = cv2.imread(item) #open image\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "            landmarks_vec = get_landmarks(gray)\n",
    "            training_data.append(landmarks_vec)\n",
    "            training_labels.append(emotion)\n",
    "    \n",
    "        for item in prediction: #repeat above process for prediction set\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            landmarks_vec = get_landmarks(gray)\n",
    "            prediction_data.append(landmarks_vec)\n",
    "            prediction_labels.append(emotion)\n",
    "\n",
    "    return training_data, training_labels, prediction_data, prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "366902ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    print(\"Marking set\")\n",
    "    X_train, y_train, X_test, y_test = make_sets()\n",
    "\n",
    "    # Turn the training set into a numpy array for the classifier\n",
    "    np_X_train = np.array(X_train)\n",
    "    np_y_train = np.array(y_train)\n",
    "    # Train SVM\n",
    "    print(\"Training SVM Classifier\")\n",
    "    clf.fit(np_X_train, np_y_train)\n",
    "\n",
    "    np_X_test = np.array(X_test)\n",
    "    np_y_test = np.array(y_test)\n",
    "    # Use score() function to get accuracy\n",
    "    print(\"Getting accuracy score --\")\n",
    "    pred_accuracy = clf.score(np_X_test, np_y_test)\n",
    "    test_pred = clf.predict(np_X_test)\n",
    "\n",
    "    print(\"Test Accuracy: \", pred_accuracy)\n",
    "\n",
    "    print(confusion_matrix(np_y_test, test_pred))\n",
    "    print(classification_report(np_y_test, test_pred))\n",
    "\n",
    "    return pred_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e027f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking set\n",
      "Training SVM Classifier\n",
      "Getting accuracy score --\n",
      "Test Accuracy:  0.981651376146789\n",
      "[[45  0  0  0  0  0  0]\n",
      " [ 0 16  0  0  0  2  0]\n",
      " [ 1  0 58  0  0  0  0]\n",
      " [ 0  0  0 25  0  0  0]\n",
      " [ 0  0  0  0 69  0  0]\n",
      " [ 0  0  0  0  0 28  0]\n",
      " [ 1  0  0  1  0  1 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.96      1.00      0.98        45\n",
      "    contempt       1.00      0.89      0.94        18\n",
      "     disgust       1.00      0.98      0.99        59\n",
      "        fear       0.96      1.00      0.98        25\n",
      "       happy       1.00      1.00      1.00        69\n",
      "     sadness       0.90      1.00      0.95        28\n",
      "    surprise       1.00      0.96      0.98        83\n",
      "\n",
      "    accuracy                           0.98       327\n",
      "   macro avg       0.97      0.98      0.97       327\n",
      "weighted avg       0.98      0.98      0.98       327\n",
      "\n",
      "Accuracy =  98.1651376146789 percent\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    accuracy = create_model()\n",
    "    print('Accuracy = ', accuracy * 100, 'percent')\n",
    "    model_file = os.path.join('models', 'model1.pkl')\n",
    "    try:\n",
    "        os.remove(model_file)\n",
    "    except OSError:\n",
    "        pass\n",
    "    output = open(model_file, 'wb')\n",
    "    pickle.dump(clf, output)\n",
    "    output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
